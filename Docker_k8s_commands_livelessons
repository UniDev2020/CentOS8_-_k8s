Docker, k8s
#                                  Docker
# About a container: https://youtu.be/EnJ7qX9fkcU
docker ps                                    show all your containers
# Installing Docker
# Remove any versions of docker:
sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
# Install required packages
sudo yum install -y yum-utils \
  device-mapper-persistent-data \
  lvm2
# Use the following command to set up the stable repository.
sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
# Install the latest version of Docker Engine - Community and containerd
sudo yum install docker-ce docker-ce-cli containerd.io
sudo systemctl enable docker
sudo systemctl start docker
systemctl status docker
########################################################################
docker info                                   verify that it is running
docker info | less                            very useful to show how much disk space has used
docker search fedora                          search for containers on Docker Hub
docker run fedora echo Hello world            start the container with command
docker ps                                     show running containers
docker ps -all                                verify operations
docker image list                             verify images
docker container ls                           verify containers
docker run -it fedora /bin/bash               start a shell on a container
# Ctrl + 'p' then Ctrl + 'q'                  detach from a running container
usermod -aG docker user                       run Docker commands as non-root user

docker pull <image>                           pull images from Docker Hub
docker run  <image>                           if it isn't locally, pull and run it
docker run --help | less                      run command has many options
docker push  <image>                          push images on Docker Hub
docker images                                 available docker images
docker rmi <image>                            remove images
docker save <image>
docker load <image>
docker attach <container>                     brings to the container environment
docker version                                compare client and server versions of Docker
docker top <container>                        provides info about processes inside Docker
docker stats <container>                      provides realtime info about activity of container
docker cp <container>:path path               copy files from container
docker exec <container> <command>             run a command inside the container
docker kill <container>
docker stop <container>                       stop a container
docker start <container>                      start a container
docker pause <container>                      suspend a container
docker unpause <container>                    unsuspend a container
docker rm <container>                         remove these containers
docker rm $( docker ps -aq)                   delete all containers
docker inspect <container>                    all the properties of a container
#########################################################################
# pull the latest image, -dit demonize a container and open in interactive
# give a name to the container, run and starting a command
docker run -dit --name centos --hostname=centos centos /bin/bash
docker attach centos
exit                                          when exit from the command in container, container stops
# filter an information about a container and show necessary parameter
docker inspect -f '{{ .NetworkSettings.IPAddress }}' <container>     show  ip address
#                               Network and containers
docker run -d --name httpd -p 8080:80 httpd                          port mapping to make them accessible
curl http://localhost:8080                                           check a connection
#
docker run -d name httpd2 -p 192.168.1.150:8090:80 httpd             IP address for the port forward
#                                     Storage
# On RHEL a host directory should have the svirt_sandbox_file_t context label for SELinux
# on the host directory use chown to set the appropriate UID and GID as owner
# for example for mariadb to have a persistent database:
mkdir -p /var/local/mysql
setenforce 0
chown -R 27:27 /var/local/mysql
docker pull mariadb
docker run --name mariadb -d -v /var/local/mysql:/var/lib/mysql \
                   -e MYSQL_USER=user -e MYSQL_PASSWORD=password \
                   -e MYSQL_DATABASE=addresses -e MYSQL_ROOT_PASSWORD=password mariadb
docker ps
ls -l /var/local/mysql/
docker -exec -it mariadb /bin/bash
ls -l /var/lib/mysql/


#                                  K8s
# ~/.kube/config    file to find info of what to connect to
# cluster: the k8s cluster, user: the autorized user
# the part of the cluster the user wants to access, typically a namespace
vim ~/.kube/config                            specify how to connect to different clusters in one config file
kubectl config view                           show current configuration
kubectl cluster-info
kubectl get                                   show resources are available
            all
            podes
            nodes
            deployments
# Connecting to a Remote Cluster
kubectl config set-cluster mycluster --server=http://ip:port --api-version=v1    to connect to the cluster
kubectl use-context mycluster                 start using it
# configure access multiple clusters for more information see the website

kubectl run                                   create a deployment or job to manage the created containers
kubectl run ngnix --image=nginx               create a deployment
kubectl run fedora --image=fedora             create a deployment
kubectl delete deployment fedora              delete a deployment
kubectl run fedora --image=fedora -- /usr/bin/sleep 3600         create a deployment with a command in it

#                                  Minikube
minikube start                                start the environment
minikube status                               status of services
minikube ssh                                  minikube prompt
                 sudo -i                      open the root shell
                 top                          different parameters
                 docker ps                    show containers
                 ps aux                       show processes
                 ps aux | localku             show a core process in minikub env
                 free -m                      memory
                 df -h                        disk spaces
minikube ip                                   show minikube ip address
minikube dashboard                            start WEB UI
minikube logs                                 give you the log information
minikube addons list                          show all addons
minikube addons enable ingress                to enable an Ingress controller
# Prepair the hostPath persistent Volume
mkdir /mnt/data
echo "Kubernetes Storage" > /mnt/data/index.html

#                                Pods with YAML files
# Specification of how to run these containers
kubectl create -f <name>.yaml                     create a pod, if some problems use --validate=false
# alternatively, use the Dashboard
kubectl get pods                                  show all running pods
kubectl get pods -o wide                               more information
kubectl describe pods <podname>                   show all details about pods
kubectl delete pod <podname>                      delete a pod
kubectl delete pod <podname>  --grace-period=0 --forec --namespace <namespace>

#                                    Cgroups
# https://selectel.ru/blog/mexanizmy-kontejnerizacii-cgroups/
# Provide a mechanism of aggregation/partitioning sets of tasks, and all their
# future children, into hierarchical groups with specialized behavior
# Limits how much you can use
# Resource metering and limiting: memory, CPU, block I/O, network, Device node access control

#                                   Namespaces
# https://selectel.ru/blog/mexanizmy-kontejnerizacii-namespaces/
# Strict isolation between resources, it allows to create separated areas
# It guarantees the secure environments that occurs on Linux Kernel level
# Limits what you can use
# Multiple ns: pid, net, mnt, uts, ipc, user, each process is in one ns of each type

# By default k8s has three namespaces: default, kube-public, kube-system
kubectl get ns                                    show namespaces
kubectl create ns secret                          create a namespace
kubectl get ns secret -o yaml                     get in yaml format for more details
kubectl get ns secret -o json                     the same in a json format

#                                   Replica Sets
# If you create a replica set by deployment, it's shouldn't scale anymore.
# kubectl scale --current-replicas=1 --replicas=3 deployment <podname>
kubectl run nginx --image-nginx                   create with image from repository
kubectl get rs                                    show replica set
kubectl get rs <rsname> -o yaml                   show more info about the replica set
kubectl scale --replicas=3 deployment nginx       scaled a replica set from deployment
                                                  can scale up and down your replicas
kubectl delete rs <rsname>                        stop an active replica set, and deployment
                                                  start it again
#                                   Deployments
# Used to create and automate replica sets
# Instruct the cluster how to create and scale applications
# Monitor instances of an application
kubectl get all
kubectl get deployments                           show the deployments
kubectl delete deployment <depname>               delete the deployment
kubectl describe deployment <depname>             information about dep
# Scale deployments
kubectl scale deployment <depname> --replicas=3   scale the deployments replicas
kubectl get deployments <depname> -o json         show all info in json, run label auto added
kubectl get pods -Lrun                            filter the pods with a running label
# if you remove a run label, a new pod will be auto created
kubectl label pods <podname> run-                 delete a label run
# Autoscale
kubectl run nginx --image=nginx
kubectl autoscale deployment nginx --min=2 --max=5 --cpu-percent=70
kubectl describe deployments nginx

#                               Troubleshooting
kubectl get deployments
kubectl describe deployment <depname>                    deployment description
kubectl describe po <podname>                            pod description
kubectl logs <podname>                                   show a pod log
kubectl logs <podname> --previous                        show logs from previous statement of a pod

#                               Object Properties
# Some properties allow by default
kubectl get {deployments|rs|pods} -o yaml         overview all properties
# apiVersion: the most recent version of the API that allow us to use this type
# exposes functionality,
# kind: the type of object
# metadata: may include items not shown here such as podAffinity and nodeAffinity
# spec: run-time parameters used by this object
# status: current run-time status information

#                                    Labels
# String that administrators can use to select or exclude objects
# Can be used to group objects which do not have an obvious relation by themselves
# For example: release:stable, release:beta, environment:dev, environment:production
# Can be used from the command line, or from YAML files to use nodeSelectors
# nodeSelectors can be used to identify where a Pod is allowed to run
kubectl label node <namenode> disktype=hdd      set a label
kubectl get nodes --show-labels                 show all labels
kubectl label pods <name> foo=bar               apply to a running pod
kubectl get pods -Lrun                          show labels set to pods
kubectl get pods -l run=<podname>               show label set to the pod
kubectl get pods -Lrun -o yaml | less           show information
kubectl label pods <podname> run-               remove the label

#                                 Rolling updates
# Is a change of properties in a deployment that needs to be pushed to the pods:
# Current number of replicas, any other properties, like version of the image to use


#                                 Daemon Set
# Controller that ensure that a single pod exists on each node in the cluster
# if a new node is added, the DaemonSet contr will add a pod automatically
# To start using it, just set kind: DaemonSet in the app YAML file

#                                  Rollback
kubectl rollout history                         overview of past activity
kubectl rollout undo                            failback
#For example:
kubectl get deployments nginx -o yaml | grep -i -A 4 strategy   show how to Rollback apply
kubectil set image deployment nginx ngnix=nginx:1.8.1 -alpine   set to use different image
kubectl describe pods nginx | grep -i image                     show changes in images
kubectl rollout history deployment nginx                        show rollout history
kubectl rollout history deployment nginx --revision=1           show rev 1
kubectl rollout history deployment nginx --revision=2           show rev 2, after changes
kubectl rollout undo deployment nginx --to-revision=1           undo the changes

#                                  Networking
# It has three different levels: Between containers within a Pod, between Pods, External exposure of services
# Connecting pods to other pods across nodes (East-West traffic), without NAT
# Service discovery and load-balancing
# Exposing services for external clients (North-South traffic)
# Segmenting networks to increase pod security
# No IP masking: the IP that the pod sees is the same as how other pods see it
#                                 Inside the Pod
# Internal communications, handled by Docker as K8s uses the Pod as the lowest entity
# Docker offers host private networking, where a virtual bridge "docker0" is created
# Docker creates a Virtual Ethernet Device for each container and this is attached ro the bridge
# eth0 within the container uses an IP addr from the docker0 bridge addr range
# As a result Docker containers can communicate to one another only if they're on the same host
# Inside your environment:
brctl show                                      show a docker bridge interfaces, virtual patch cables
docker ps                                       show all docker containers
docker inspect <container>                      show all the info and Network Settings
# in k8s
kubectl get pods -o wide                        show ip addr assigned by k8s
#                             Pod to pod networking
# k8s uses CNI plugin to implement Pod-to-Pod
# CNI plugins provide 3 types of networking: layer 2, layer 3, overlay networking (SoftwareDefinedNetworking)
# layer 2: Pods and nodes see subnets used for pod IP addr as a single layer 2 domain
# Pod-to-Pod communication happens through ARP (AddressResolutionProtocol)
# Also need a bridge plugin, it should exists on all physical k8s hosts
# Layer 2 configuration isn't scalable
# Layer 3 uses routing through different plugins (flannel, calico, etc.)
# Overlay uses plugins, and use encapsulation - which looks like VPN - to send packets between pods
# VXLAN, GRE can be used to do so
#                                 Exposing services
# It's a different object to expose functionality externally
# Refers to a set of pods which is based on labels
# Services work with publicly accessible IP addresses

#                                  Accessing Pods
# Kubernetes Proxy, to access a k8s service locally without exposing it
kubectl proxy &                                 start proxy in bg
curl http://localhost:8001/version              API interface
curl http://localhost:8001/api/v1               investigate through API
curl http://localhost:8001/api/v1/namespaces/default/services

#                                  Port-forwarding
# Provides an easy way to connect to services running in the pod, it works on pods
# exposed port will be available on th k8s management workstation
kubectl port-forward --help | less              documentation
kubectl port-forward http 8000:80               forwards port 80 on the pod to 8000 on host

#                                     Services
# Default service is created for K8s, custom services can be created using kubectl expose
# Label selectors can be used to determine which pods are added to a service
kubectl expose --help                            documentation and examples
kubectl describe pod <podname>                   it can contains label sections
kubectl label pod <podname> dept=sales           set the label
kubectl expose pod <podname> --type="NodePort" --port=80      expose pods to the service
kubectl expose deployment <depname> --port=80 --type=NodePort
kubectl get services                             verify that pod has been exposed
kubectl get svc <name> -o yaml                   more info
kubectl delete service <name>                    un-expose it, not delete the pod
#                                        DNS
# DNS included, DNS name lookup from within a pod to an exposed service happens auto
kubectl exec -it busybox -- nslookup httpd       run nslookup within deployment
kubectl exec <podname> cat /etc/resolv.conf      show the info which use to dns
#                                    Service type
# Determine how service are accessed
# ClusterIP: default, provides internal access only by exposing the service on a cluster-internal IP
# NodePort: exposes a port on K8s hosts, each node will proxy that port into the Service
# LoadBalancer: available in public cloud solutions. In private, if K8s provise a plugin
#                                       Ingress
# Uses to give services externally reachable URL
# Best support is available for the Nginx controller
# https://kubernetes.io/docs/concepts/service-networking/ingress/ for up to date info
# Using Ingress: verify service availability, create an Ingress YAML file, add the Ingress
# object to the API, access the service using the Ingress rule
kubectl create -f nginx.yaml                    create an Ingress
kubectl get ingress                             show ingresses
kubectl get ingress nginx-ingress -o yaml       more details about it
curl -k https://<ip>/nginx                      connect to insecure mode

#                                   Using Volumes
# Accessing volumes:
# RWO (ReadWriteOnce) allows read-write access by one node
# ROX (ReadOnlyMany) allows read-only by multiple nodes
# RWX (ReadWriteMany) allows read-write by many nodes
# Create Volume
kubectl create -f volumes.yaml --validate=false
kubectl get pods
kubectl describe pods morevol | less
# Test that you can use it
kubectl exec -it morevol -c centos -- touch /centos/test
kubectl exec -it morevol -c centos2 -- ls -l /centos2
#                                     Persistent Volumes
# PV is an independent K8s resource
# PV isn't dependent from any pod and therefore survives a pod
# PVClaim is a request to use PV, spec storage prop can be req
# Lifecycle
# Provisioning: PVs can be provisioned statically or dynamically
# Binding: the user requests access to a PV using a PVC
# Using: pods use claims as volumes
# Reclaiming: what happens after the user is done
# Volumes can be in different states:
# Retain: keeps data intact
# Delete: deletes the API object as well as the storage
# Recycle: removes contents of the storage mountpoint
# Create a PersistentVolume
# Create pv.yaml
kubectl create -f pv.yaml
kubectl get pv
# Create a PVClaim
# Create pvc.yaml
kubectl create -f pvc.yaml
kubectl get pv pv-volume
kubectl get pvc pv-claim
# Create a Pod
# Create pv-pod.yaml
kubectl create -f pv-pod.yaml
kubectl get pod pv-pod
kubectl exec -it pv-pod -- /bin/bash
apt-get update; yapt-get install curl
curl localhost




